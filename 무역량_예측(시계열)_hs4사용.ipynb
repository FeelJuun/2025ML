{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "학습"
      ],
      "metadata": {
        "id": "SFUbGTJmkWh5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtEwIDM_OmxT",
        "outputId": "553e7308-6962-45ad-e41c-08ce3a108fa1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "scan leaders (multi-criteria): 100%|██████████| 100/100 [00:25<00:00,  3.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pairs (multi-criteria, relaxed): 5427\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001782 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2833\n",
            "[LightGBM] [Info] Number of data points in the train set: 207558, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score 12.076956\n",
            "train_rows=207558 , pairs=5427\n",
            "saved: models_new_arch/global_new_arch.txt , models_new_arch/meta_new_arch.json\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import re\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from joblib import dump\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ==================== 설정 / 하이퍼파라미터 ====================\n",
        "\n",
        "MODEL_DIR = Path(\"./models_new_arch\")\n",
        "GLOBAL_MODEL_PATH = MODEL_DIR / \"global_new_arch.txt\"\n",
        "META_PATH = MODEL_DIR / \"meta_new_arch.json\"\n",
        "\n",
        "# 공행성 탐색\n",
        "MAX_LAG = 6\n",
        "MIN_NONZERO = 10       # 한 시계열에서 0이 아닌 월 개수 최소\n",
        "MIN_LEN = 24           # 상관 계산에 사용할 최소 길이\n",
        "RECENT_WINDOW = 12     # 최근 상관 계산 창 크기(개월)\n",
        "\n",
        "CORR_FULL_MIN = 0.20   # 전체 구간 상관 최소 (완화)\n",
        "SCORE_MIN = 0.0        # 복합 점수 최소 (완화)\n",
        "TOPK_PER_B = None      # B당 상위 K만 유지하지 않고, 조건 만족 쌍을 모두 사용\n",
        "\n",
        "# Δlog 클램프 및 naive 블렌딩\n",
        "CLAMP_Q = 0.80         # |Δlog| 분위수\n",
        "ALPHA_NAIVE = 0.20     # 최종: (1-α)*model + α*naive\n",
        "\n",
        "# 전역 LightGBM 하이퍼파라미터\n",
        "LGBM_PARAMS = dict(\n",
        "    n_estimators=900,\n",
        "    learning_rate=0.02,\n",
        "    max_depth=-1,\n",
        "    num_leaves=31,\n",
        "    subsample=0.9,\n",
        "    colsample_bytree=0.9,\n",
        "    reg_lambda=1.0,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        ")\n",
        "\n",
        "\n",
        "# ==================== 유틸 ====================\n",
        "\n",
        "def _find_file(fname: str) -> Path:\n",
        "    p = Path(fname)\n",
        "    if p.exists():\n",
        "        return p\n",
        "    p2 = Path(\"/mnt/data\") / fname\n",
        "    if p2.exists():\n",
        "        return p2\n",
        "    raise FileNotFoundError(fname)\n",
        "\n",
        "\n",
        "def _safe_id(s) -> str:\n",
        "    return re.sub(r\"[^A-Za-z0-9_-]\", \"_\", str(s))[:64]\n",
        "\n",
        "\n",
        "def safe_corr(x: np.ndarray, y: np.ndarray) -> float:\n",
        "    if x.size == 0 or y.size == 0:\n",
        "        return 0.0\n",
        "    sx = float(np.std(x))\n",
        "    sy = float(np.std(y))\n",
        "    if sx == 0.0 or sy == 0.0:\n",
        "        return 0.0\n",
        "    return float(np.corrcoef(x, y)[0, 1])\n",
        "\n",
        "\n",
        "def load_monthly_and_hs4(train_csv: str):\n",
        "    \"\"\"\n",
        "    monthly: item_id, year, month, hs4, value(합산), ym\n",
        "    pivot_train: item_id × ym (<= 2025-07)\n",
        "    item_to_hs4: {item_id(str): hs4(str)}\n",
        "    hs4_month_logmean: \"hs4|month\" -> mean log1p(value)\n",
        "    hs4_global_logmean: hs4 -> mean log1p(value)\n",
        "    global_logmean: 전체 mean log1p(value)\n",
        "    \"\"\"\n",
        "    p = _find_file(train_csv)\n",
        "    df = pd.read_csv(\n",
        "        p,\n",
        "        dtype={\n",
        "            \"item_id\": str,\n",
        "            \"year\": int,\n",
        "            \"month\": int,\n",
        "            \"hs4\": str,\n",
        "            \"value\": float,\n",
        "        },\n",
        "    )\n",
        "\n",
        "    monthly = (\n",
        "        df.groupby([\"item_id\", \"year\", \"month\"], as_index=False)\n",
        "        .agg({\"value\": \"sum\", \"hs4\": \"first\"})\n",
        "    )\n",
        "    monthly[\"ym\"] = pd.to_datetime(\n",
        "        monthly[\"year\"].astype(str) + \"-\" + monthly[\"month\"].astype(str).str.zfill(2)\n",
        "    )\n",
        "\n",
        "    pivot = (\n",
        "        monthly.pivot(index=\"item_id\", columns=\"ym\", values=\"value\")\n",
        "        .fillna(0.0)\n",
        "        .sort_index(axis=1)\n",
        "    )\n",
        "    pivot_train = pivot.loc[:, pivot.columns <= pd.Timestamp(\"2025-07-01\")]\n",
        "\n",
        "    def _mode_or_first(s):\n",
        "        m = s.mode()\n",
        "        return m.iloc[0] if not m.empty else s.iloc[0]\n",
        "\n",
        "    item_hs4_s = monthly.groupby(\"item_id\")[\"hs4\"].agg(_mode_or_first)\n",
        "    item_to_hs4 = item_hs4_s.to_dict()\n",
        "\n",
        "    monthly[\"logv\"] = np.log1p(monthly[\"value\"])\n",
        "    grp_hm = monthly.groupby([\"hs4\", \"month\"])[\"logv\"].mean()\n",
        "    hs4_month_logmean = {f\"{h}|{m}\": float(v) for (h, m), v in grp_hm.items()}\n",
        "\n",
        "    grp_h = monthly.groupby(\"hs4\")[\"logv\"].mean()\n",
        "    hs4_global_logmean = {h: float(v) for h, v in grp_h.items()}\n",
        "\n",
        "    global_logmean = float(monthly[\"logv\"].mean())\n",
        "\n",
        "    return pivot_train, item_to_hs4, hs4_month_logmean, hs4_global_logmean, global_logmean\n",
        "\n",
        "\n",
        "# ==================== 1) 공행성쌍 탐색 (복합 점수, 완화된 선택) ====================\n",
        "\n",
        "def find_comovement_pairs_multi(\n",
        "    pivot_val: pd.DataFrame,\n",
        "    max_lag: int,\n",
        "    min_nonzero: int,\n",
        "    min_len: int,\n",
        "    recent_window: int,\n",
        "    corr_full_min: float,\n",
        "    score_min: float,\n",
        "    topk_per_B=None,\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    각 (A,B)에 대해:\n",
        "      - lag 1..max_lag 로 log1p 기준 cross-corr\n",
        "      - 전체 상관, 최근 상관, 전/후반기 안정성으로 점수 계산\n",
        "      - corr_full_min, score_min 조건을 만족하는 쌍 모두 사용\n",
        "        (topk_per_B가 None이 아니면 B별 상위 K만 유지)\n",
        "    \"\"\"\n",
        "    items = pivot_val.index.to_list()\n",
        "    dates = pivot_val.columns.to_list()\n",
        "    T = len(dates)\n",
        "    pivot_log = np.log1p(pivot_val)\n",
        "\n",
        "    rows = []\n",
        "\n",
        "    for A in tqdm(items, desc=\"scan leaders (multi-criteria)\"):\n",
        "        x_val = pivot_val.loc[A].values.astype(float)\n",
        "        if np.count_nonzero(x_val) < min_nonzero:\n",
        "            continue\n",
        "        x_log = pivot_log.loc[A].values.astype(float)\n",
        "\n",
        "        for B in items:\n",
        "            if B == A:\n",
        "                continue\n",
        "            y_val = pivot_val.loc[B].values.astype(float)\n",
        "            if np.count_nonzero(y_val) < min_nonzero:\n",
        "                continue\n",
        "            y_log = pivot_log.loc[B].values.astype(float)\n",
        "\n",
        "            best = None\n",
        "\n",
        "            for lag in range(1, max_lag + 1):\n",
        "                if T - lag < min_len:\n",
        "                    continue\n",
        "\n",
        "                x = x_log[:-lag]\n",
        "                y = y_log[lag:]\n",
        "                L = len(x)\n",
        "                if L < min_len:\n",
        "                    continue\n",
        "\n",
        "                corr_full = safe_corr(x, y)\n",
        "\n",
        "                half = L // 2\n",
        "                if half >= 2 and (L - half) >= 2:\n",
        "                    corr1 = safe_corr(x[:half], y[:half])\n",
        "                    corr2 = safe_corr(x[half:], y[half:])\n",
        "                else:\n",
        "                    corr1 = corr2 = corr_full\n",
        "                stability = abs(corr1 - corr2)\n",
        "\n",
        "                rw = min(recent_window, L)\n",
        "                xr = x[-rw:]\n",
        "                yr = y[-rw:]\n",
        "                corr_recent = safe_corr(xr, yr)\n",
        "\n",
        "                score = (\n",
        "                    abs(corr_full)\n",
        "                    + 0.5 * abs(corr_recent)\n",
        "                    - 0.3 * stability\n",
        "                )\n",
        "\n",
        "                if (best is None) or (score > best[\"score\"]):\n",
        "                    best = {\n",
        "                        \"lag\": lag,\n",
        "                        \"corr_full\": corr_full,\n",
        "                        \"corr_recent\": corr_recent,\n",
        "                        \"stability\": stability,\n",
        "                        \"score\": score,\n",
        "                    }\n",
        "\n",
        "            if best is None:\n",
        "                continue\n",
        "\n",
        "            rows.append(\n",
        "                {\n",
        "                    \"leading_item_id\": A,\n",
        "                    \"following_item_id\": B,\n",
        "                    \"best_lag\": int(best[\"lag\"]),\n",
        "                    \"corr_full\": float(best[\"corr_full\"]),\n",
        "                    \"corr_recent\": float(best[\"corr_recent\"]),\n",
        "                    \"stability\": float(best[\"stability\"]),\n",
        "                    \"score\": float(best[\"score\"]),\n",
        "                }\n",
        "            )\n",
        "\n",
        "    df_all = pd.DataFrame(rows)\n",
        "    if df_all.empty:\n",
        "        return df_all\n",
        "\n",
        "    df_all[\"corr_full_abs\"] = df_all[\"corr_full\"].abs()\n",
        "\n",
        "    # 조건 필터\n",
        "    cond = (df_all[\"corr_full_abs\"] >= corr_full_min) & (df_all[\"score\"] >= score_min)\n",
        "    df = df_all[cond]\n",
        "\n",
        "    # topk_per_B가 지정되면 B별 상위 K만 유지 (지금은 None, 즉 전체 사용)\n",
        "    if topk_per_B is not None:\n",
        "        selected = []\n",
        "        for B, grp in df.groupby(\"following_item_id\"):\n",
        "            grp_sorted = grp.sort_values(\"score\", ascending=False)\n",
        "            selected.append(grp_sorted.head(topk_per_B))\n",
        "        df = pd.concat(selected, ignore_index=True)\n",
        "    else:\n",
        "        df = df.reset_index(drop=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# ==================== 2) 전역 logB_{t+1} LightGBM 학습 ====================\n",
        "\n",
        "def build_training_data_global(\n",
        "    pivot: pd.DataFrame,\n",
        "    pairs: pd.DataFrame,\n",
        "    item_to_hs4: dict,\n",
        "    hs4_month_logmean: dict,\n",
        "    hs4_global_logmean: dict,\n",
        "    global_logmean: float,\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    전역 LightGBM 학습용 데이터.\n",
        "\n",
        "    X:\n",
        "      - logB_t, logB_t_1, logB_t_2\n",
        "      - logA_t_lag, logA_t_lag_1\n",
        "      - corr_full, corr_recent, stability, score, best_lag\n",
        "      - sin_m, cos_m (다음달)\n",
        "      - hs4A_mlog_curr (A, 현재월), hs4B_mlog_next (B, 다음달)\n",
        "    y:\n",
        "      - log1p(B_{t+1})\n",
        "    \"\"\"\n",
        "    months = pivot.columns.to_list()\n",
        "    n_months = len(months)\n",
        "\n",
        "    rows = []\n",
        "\n",
        "    for r in pairs.itertuples(index=False):\n",
        "        A = r.leading_item_id\n",
        "        B = r.following_item_id\n",
        "        lag = int(r.best_lag)\n",
        "        corr_full = float(r.corr_full)\n",
        "        corr_recent = float(r.corr_recent)\n",
        "        stability = float(r.stability)\n",
        "        score = float(r.score)\n",
        "\n",
        "        if (A not in pivot.index) or (B not in pivot.index):\n",
        "            continue\n",
        "\n",
        "        sA = pivot.loc[A].values.astype(float)\n",
        "        sB = pivot.loc[B].values.astype(float)\n",
        "\n",
        "        hs4_A = item_to_hs4.get(A, None)\n",
        "        hs4_B = item_to_hs4.get(B, None)\n",
        "\n",
        "        for t in range(max(lag, 2), n_months - 1):\n",
        "            B_t = sB[t]\n",
        "            B_t_1 = sB[t - 1]\n",
        "            B_t_2 = sB[t - 2]\n",
        "            B_t1 = sB[t + 1]\n",
        "\n",
        "            A_t_lag = sA[t - lag]\n",
        "            if (t - lag - 1) >= 0:\n",
        "                A_t_lag_1 = sA[t - lag - 1]\n",
        "            else:\n",
        "                A_t_lag_1 = A_t_lag\n",
        "\n",
        "            logB_t = np.log1p(B_t)\n",
        "            logB_t_1 = np.log1p(B_t_1)\n",
        "            logB_t_2 = np.log1p(B_t_2)\n",
        "            logB_t1 = np.log1p(B_t1)\n",
        "            logA_t_lag = np.log1p(A_t_lag)\n",
        "            logA_t_lag_1 = np.log1p(A_t_lag_1)\n",
        "\n",
        "            m_curr = months[t].month\n",
        "            m_next = months[t + 1].month\n",
        "            sin_m = np.sin(2 * np.pi * m_next / 12.0)\n",
        "            cos_m = np.cos(2 * np.pi * m_next / 12.0)\n",
        "\n",
        "            if hs4_A is not None:\n",
        "                key_A_curr = f\"{hs4_A}|{m_curr}\"\n",
        "                mlog_A_curr = hs4_month_logmean.get(\n",
        "                    key_A_curr,\n",
        "                    hs4_global_logmean.get(hs4_A, global_logmean),\n",
        "                )\n",
        "            else:\n",
        "                mlog_A_curr = global_logmean\n",
        "\n",
        "            if hs4_B is not None:\n",
        "                key_B_next = f\"{hs4_B}|{m_next}\"\n",
        "                mlog_B_next = hs4_month_logmean.get(\n",
        "                    key_B_next,\n",
        "                    hs4_global_logmean.get(hs4_B, global_logmean),\n",
        "                )\n",
        "            else:\n",
        "                mlog_B_next = global_logmean\n",
        "\n",
        "            rows.append(\n",
        "                {\n",
        "                    \"logB_t\": logB_t,\n",
        "                    \"logB_t_1\": logB_t_1,\n",
        "                    \"logB_t_2\": logB_t_2,\n",
        "                    \"logA_t_lag\": logA_t_lag,\n",
        "                    \"logA_t_lag_1\": logA_t_lag_1,\n",
        "                    \"corr_full\": corr_full,\n",
        "                    \"corr_recent\": corr_recent,\n",
        "                    \"stability\": stability,\n",
        "                    \"score\": score,\n",
        "                    \"best_lag\": float(lag),\n",
        "                    \"sin_m\": sin_m,\n",
        "                    \"cos_m\": cos_m,\n",
        "                    \"hs4A_mlog_curr\": float(mlog_A_curr),\n",
        "                    \"hs4B_mlog_next\": float(mlog_B_next),\n",
        "                    \"target_logB_next\": logB_t1,\n",
        "                    \"B\": B,\n",
        "                }\n",
        "            )\n",
        "\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "# ==================== 메인 학습 ====================\n",
        "\n",
        "def main():\n",
        "    MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    pivot_train, item_to_hs4, hs4_month_logmean, hs4_global_logmean, global_logmean = \\\n",
        "        load_monthly_and_hs4(\"train.csv\")\n",
        "\n",
        "    pivot_log = np.log1p(pivot_train)\n",
        "\n",
        "    # 1) 공행성쌍 (완화된 multi-criteria)\n",
        "    pairs = find_comovement_pairs_multi(\n",
        "        pivot_val=pivot_train,\n",
        "        max_lag=MAX_LAG,\n",
        "        min_nonzero=MIN_NONZERO,\n",
        "        min_len=MIN_LEN,\n",
        "        recent_window=RECENT_WINDOW,\n",
        "        corr_full_min=CORR_FULL_MIN,\n",
        "        score_min=SCORE_MIN,\n",
        "        topk_per_B=TOPK_PER_B,\n",
        "    )\n",
        "    print(\"pairs (multi-criteria, relaxed):\", len(pairs))\n",
        "\n",
        "    # 2) 전역 LightGBM 학습\n",
        "    df_train = build_training_data_global(\n",
        "        pivot_train,\n",
        "        pairs,\n",
        "        item_to_hs4,\n",
        "        hs4_month_logmean,\n",
        "        hs4_global_logmean,\n",
        "        global_logmean,\n",
        "    )\n",
        "    if df_train.empty:\n",
        "        meta = {\n",
        "            \"pairs\": [],\n",
        "            \"global_feature_cols\": [],\n",
        "            \"clamp_q\": CLAMP_Q,\n",
        "            \"alpha_naive\": ALPHA_NAIVE,\n",
        "            \"clamp_by_B\": {},\n",
        "            \"item_to_hs4\": item_to_hs4,\n",
        "            \"hs4_month_logmean\": hs4_month_logmean,\n",
        "            \"hs4_global_logmean\": hs4_global_logmean,\n",
        "            \"global_logmean\": global_logmean,\n",
        "            \"hp\": {\n",
        "                \"MAX_LAG\": MAX_LAG,\n",
        "                \"MIN_NONZERO\": MIN_NONZERO,\n",
        "                \"MIN_LEN\": MIN_LEN,\n",
        "                \"RECENT_WINDOW\": RECENT_WINDOW,\n",
        "                \"CORR_FULL_MIN\": CORR_FULL_MIN,\n",
        "                \"SCORE_MIN\": SCORE_MIN,\n",
        "                \"TOPK_PER_B\": TOPK_PER_B,\n",
        "            },\n",
        "        }\n",
        "        with open(META_PATH, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(meta, f, ensure_ascii=False, indent=2)\n",
        "        print(\"No training rows. Saved empty meta.\")\n",
        "        return\n",
        "\n",
        "    feature_cols = [\n",
        "        \"logB_t\",\n",
        "        \"logB_t_1\",\n",
        "        \"logB_t_2\",\n",
        "        \"logA_t_lag\",\n",
        "        \"logA_t_lag_1\",\n",
        "        \"corr_full\",\n",
        "        \"corr_recent\",\n",
        "        \"stability\",\n",
        "        \"score\",\n",
        "        \"best_lag\",\n",
        "        \"sin_m\",\n",
        "        \"cos_m\",\n",
        "        \"hs4A_mlog_curr\",\n",
        "        \"hs4B_mlog_next\",\n",
        "    ]\n",
        "    X = df_train[feature_cols].values\n",
        "    y = df_train[\"target_logB_next\"].values\n",
        "\n",
        "    lgbm = LGBMRegressor(**LGBM_PARAMS)\n",
        "    lgbm.fit(X, y)\n",
        "    lgbm.booster_.save_model(str(GLOBAL_MODEL_PATH))\n",
        "\n",
        "    # 3) follower별 Δlog 분포로 클램프 값 계산\n",
        "    clamp_by_B = {}\n",
        "    for B in pivot_train.index:\n",
        "        sB = pivot_train.loc[B].values.astype(float)\n",
        "        logs = np.log1p(sB)\n",
        "        d = np.diff(logs)\n",
        "        if len(d) == 0:\n",
        "            c = 0.0\n",
        "        else:\n",
        "            c = float(np.quantile(np.abs(d), CLAMP_Q))\n",
        "        if c < 0.05:\n",
        "            c = 0.05\n",
        "        clamp_by_B[B] = c\n",
        "\n",
        "    # 4) 메타 저장\n",
        "    meta = {\n",
        "        \"pairs\": pairs.to_dict(orient=\"records\"),\n",
        "        \"global_feature_cols\": feature_cols,\n",
        "        \"clamp_q\": CLAMP_Q,\n",
        "        \"alpha_naive\": ALPHA_NAIVE,\n",
        "        \"clamp_by_B\": clamp_by_B,\n",
        "        \"item_to_hs4\": item_to_hs4,\n",
        "        \"hs4_month_logmean\": hs4_month_logmean,\n",
        "        \"hs4_global_logmean\": hs4_global_logmean,\n",
        "        \"global_logmean\": global_logmean,\n",
        "        \"hp\": {\n",
        "            \"MAX_LAG\": MAX_LAG,\n",
        "            \"MIN_NONZERO\": MIN_NONZERO,\n",
        "            \"MIN_LEN\": MIN_LEN,\n",
        "            \"RECENT_WINDOW\": RECENT_WINDOW,\n",
        "            \"CORR_FULL_MIN\": CORR_FULL_MIN,\n",
        "            \"SCORE_MIN\": SCORE_MIN,\n",
        "            \"TOPK_PER_B\": TOPK_PER_B,\n",
        "        },\n",
        "    }\n",
        "    with open(META_PATH, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(meta, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print(f\"train_rows={len(df_train)} , pairs={len(pairs)}\")\n",
        "    print(f\"saved: {GLOBAL_MODEL_PATH} , {META_PATH}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "추론"
      ],
      "metadata": {
        "id": "wLOVuPdNkRYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from lightgbm import Booster\n",
        "\n",
        "MODEL_DIR = Path(\"./models_new_arch\")\n",
        "GLOBAL_MODEL_PATH = MODEL_DIR / \"global_new_arch.txt\"\n",
        "META_PATH = MODEL_DIR / \"meta_new_arch.json\"\n",
        "\n",
        "\n",
        "def _find_file(fname: str) -> Path:\n",
        "    p = Path(fname)\n",
        "    if p.exists():\n",
        "        return p\n",
        "    p2 = Path(\"/mnt/data\") / fname\n",
        "    if p2.exists():\n",
        "        return p2\n",
        "    raise FileNotFoundError(fname)\n",
        "\n",
        "\n",
        "def load_pivot_full(train_csv: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    item_id × ym 피벗 (2025-08까지 열 보강).\n",
        "    index: item_id(str), columns: 월(1일 Timestamp)\n",
        "    \"\"\"\n",
        "    p = _find_file(train_csv)\n",
        "    df = pd.read_csv(\n",
        "        p,\n",
        "        dtype={\"item_id\": str, \"year\": int, \"month\": int, \"value\": float},\n",
        "    )\n",
        "    monthly = df.groupby([\"item_id\", \"year\", \"month\"], as_index=False)[\"value\"].sum()\n",
        "    monthly[\"ym\"] = pd.to_datetime(\n",
        "        monthly[\"year\"].astype(str) + \"-\" + monthly[\"month\"].astype(str).str.zfill(2)\n",
        "    )\n",
        "    start = monthly[\"ym\"].min()\n",
        "    end = pd.Timestamp(\"2025-08-01\")\n",
        "    idx = pd.date_range(start=start, end=end, freq=\"MS\")\n",
        "    items = np.sort(monthly[\"item_id\"].unique())\n",
        "\n",
        "    pivot = pd.DataFrame(0.0, index=items, columns=idx, dtype=float)\n",
        "    for iid, g in monthly.groupby(\"item_id\"):\n",
        "        s = g.set_index(\"ym\")[\"value\"].reindex(idx, fill_value=0.0).astype(float)\n",
        "        pivot.loc[iid, :] = s.values\n",
        "\n",
        "    pivot = pivot.sort_index(axis=1)\n",
        "    return pivot\n",
        "\n",
        "\n",
        "def main():\n",
        "    with open(META_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "        meta = json.load(f)\n",
        "\n",
        "    pairs = pd.DataFrame(meta.get(\"pairs\", []))\n",
        "    if pairs.empty:\n",
        "        sub = pd.DataFrame(\n",
        "            columns=[\"leading_item_id\", \"following_item_id\", \"value\"]\n",
        "        )\n",
        "        sub.to_csv(\"submission_new_arch.csv\", index=False)\n",
        "        print(\"No pairs in meta. Wrote empty submission_new_arch.csv\")\n",
        "        return\n",
        "\n",
        "    feature_cols = meta.get(\"global_feature_cols\", [])\n",
        "    alpha = float(meta.get(\"alpha_naive\", 0.20))\n",
        "    clamp_by_B = meta.get(\"clamp_by_B\", {})\n",
        "\n",
        "    item_to_hs4 = meta.get(\"item_to_hs4\", {})\n",
        "    hs4_month_logmean = meta.get(\"hs4_month_logmean\", {})\n",
        "    hs4_global_logmean = meta.get(\"hs4_global_logmean\", {})\n",
        "    global_logmean = float(meta.get(\"global_logmean\", 0.0))\n",
        "\n",
        "    global_model = Booster(model_file=str(GLOBAL_MODEL_PATH))\n",
        "\n",
        "    pivot_full = load_pivot_full(\"train.csv\")\n",
        "    months = pivot_full.columns.to_list()\n",
        "    assert months[-1] == pd.Timestamp(\"2025-08-01\"), \"마지막 열은 2025-08-01이어야 합니다.\"\n",
        "    t_last_train = len(months) - 2  # 2025-07 index\n",
        "\n",
        "    out_rows = []\n",
        "\n",
        "    for r in pairs.itertuples(index=False):\n",
        "        A = r.leading_item_id\n",
        "        B = r.following_item_id\n",
        "        lag = int(r.best_lag)\n",
        "        corr_full = float(r.corr_full)\n",
        "        corr_recent = float(r.corr_recent)\n",
        "        stability = float(r.stability)\n",
        "        score = float(r.score)\n",
        "\n",
        "        if (A not in pivot_full.index) or (B not in pivot_full.index):\n",
        "            continue\n",
        "\n",
        "        sA = pivot_full.loc[A].values.astype(float)\n",
        "        sB = pivot_full.loc[B].values.astype(float)\n",
        "\n",
        "        B_t = sB[t_last_train]\n",
        "        B_t_1 = sB[t_last_train - 1] if t_last_train - 1 >= 0 else 0.0\n",
        "        B_t_2 = sB[t_last_train - 2] if t_last_train - 2 >= 0 else 0.0\n",
        "\n",
        "        if (t_last_train - lag) >= 0:\n",
        "            A_t_lag = sA[t_last_train - lag]\n",
        "        else:\n",
        "            A_t_lag = 0.0\n",
        "\n",
        "        if (t_last_train - lag - 1) >= 0:\n",
        "            A_t_lag_1 = sA[t_last_train - lag - 1]\n",
        "        else:\n",
        "            A_t_lag_1 = A_t_lag\n",
        "\n",
        "        logB_t = np.log1p(B_t)\n",
        "        logB_t_1 = np.log1p(B_t_1)\n",
        "        logB_t_2 = np.log1p(B_t_2)\n",
        "        logA_t_lag = np.log1p(A_t_lag)\n",
        "        logA_t_lag_1 = np.log1p(A_t_lag_1)\n",
        "\n",
        "        m_curr = months[t_last_train].month   # 2025-07\n",
        "        m_next = months[t_last_train + 1].month  # 2025-08\n",
        "        sin_m = np.sin(2 * np.pi * m_next / 12.0)\n",
        "        cos_m = np.cos(2 * np.pi * m_next / 12.0)\n",
        "\n",
        "        hs4_A = item_to_hs4.get(A, None)\n",
        "        hs4_B = item_to_hs4.get(B, None)\n",
        "\n",
        "        if hs4_A is not None:\n",
        "            key_A_curr = f\"{hs4_A}|{m_curr}\"\n",
        "            mlog_A_curr = hs4_month_logmean.get(\n",
        "                key_A_curr,\n",
        "                hs4_global_logmean.get(hs4_A, global_logmean),\n",
        "            )\n",
        "        else:\n",
        "            mlog_A_curr = global_logmean\n",
        "\n",
        "        if hs4_B is not None:\n",
        "            key_B_next = f\"{hs4_B}|{m_next}\"\n",
        "            mlog_B_next = hs4_month_logmean.get(\n",
        "                key_B_next,\n",
        "                hs4_global_logmean.get(hs4_B, global_logmean),\n",
        "            )\n",
        "        else:\n",
        "            mlog_B_next = global_logmean\n",
        "\n",
        "        feat_dict = {\n",
        "            \"logB_t\": logB_t,\n",
        "            \"logB_t_1\": logB_t_1,\n",
        "            \"logB_t_2\": logB_t_2,\n",
        "            \"logA_t_lag\": logA_t_lag,\n",
        "            \"logA_t_lag_1\": logA_t_lag_1,\n",
        "            \"corr_full\": corr_full,\n",
        "            \"corr_recent\": corr_recent,\n",
        "            \"stability\": stability,\n",
        "            \"score\": score,\n",
        "            \"best_lag\": float(lag),\n",
        "            \"sin_m\": sin_m,\n",
        "            \"cos_m\": cos_m,\n",
        "            \"hs4A_mlog_curr\": float(mlog_A_curr),\n",
        "            \"hs4B_mlog_next\": float(mlog_B_next),\n",
        "        }\n",
        "\n",
        "        X = np.array([[feat_dict[col] for col in feature_cols]], dtype=float)\n",
        "        log_pred = float(global_model.predict(X)[0])\n",
        "\n",
        "        d_log_pred = log_pred - logB_t\n",
        "        cB = float(clamp_by_B.get(B, 0.1))\n",
        "        d_log_clamped = float(np.clip(d_log_pred, -cB, cB))\n",
        "        log_pred_clamped = logB_t + d_log_clamped\n",
        "\n",
        "        y_pred = float(np.expm1(log_pred_clamped))\n",
        "        y_final = (1.0 - alpha) * y_pred + alpha * B_t\n",
        "        y_final = max(0.0, y_final)\n",
        "\n",
        "        out_rows.append(\n",
        "            {\n",
        "                \"leading_item_id\": A,\n",
        "                \"following_item_id\": B,\n",
        "                \"value\": int(np.rint(y_final)),\n",
        "            }\n",
        "        )\n",
        "\n",
        "    sub = pd.DataFrame(\n",
        "        out_rows, columns=[\"leading_item_id\", \"following_item_id\", \"value\"]\n",
        "    )\n",
        "    sub.to_csv(\"submission_new_arch.csv\", index=False)\n",
        "    print(f\"Wrote submission_new_arch.csv with {len(sub)} rows\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DS6YYPASi4i",
        "outputId": "d14f863c-f05a-463c-d3e5-d13d66527563"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_new_arch.csv with 5427 rows\n"
          ]
        }
      ]
    }
  ]
}